{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Uses a list of tile IDs to scrape the corresponding LAZ files from Kentuckyâ€™s LiDAR database into a GCS bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from multiprocessing import Pool\n",
        "import time\n",
        "import math\n",
        "from google.colab import auth\n",
        "from google.cloud import storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PROJECT_ID = 'skytruth-tech'\n",
        "GCLOUD_BUCKET = 'mountaintop_mining'\n",
        "MAIN_DIR = 'lidar_data'\n",
        "TILE_IDS_DIR = MAIN_DIR + '/tile_IDs'\n",
        "TILE_INDEX = 'KY_tile_index_intersect.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM-8C51gUJuq"
      },
      "outputs": [],
      "source": [
        "# Authenticate GCS\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZ73FzHbUNRg"
      },
      "outputs": [],
      "source": [
        "# Initialize Google Cloud Storage client and access bucket\n",
        "client = storage.Client(project=PROJECT_ID)\n",
        "bucket = client.get_bucket(GCLOUD_BUCKET)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OB-V5fRfwnaX"
      },
      "outputs": [],
      "source": [
        "# Get table of tile IDs with Phase 1 and 2 download links\n",
        "csv = bucket.blob(f'{TILE_IDS_DIR}/{TILE_INDEX}')\n",
        "csv.download_to_filename(f'/content/{TILE_INDEX}')\n",
        "df = pd.read_csv(f'/content/{TILE_INDEX}')\n",
        "rows = df.to_dict('records')\n",
        "print(df['Tile_ID'].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foYjz0O-kko1"
      },
      "outputs": [],
      "source": [
        "# Function to test if the Phase 2 download url exists\n",
        "def is_nan(value):\n",
        "    if isinstance(value, float) and math.isnan(value):\n",
        "        return True\n",
        "    elif isinstance(value, str) and value.lower() == 'nan':\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJr2L5mcdh1G"
      },
      "outputs": [],
      "source": [
        "# Scraper function: downloads the Phase 2 las file if it exists, otherwise downloads the Phase 1 las file\n",
        "def scrape(row):\n",
        "  tile_ID = row['Tile_ID']\n",
        "  if is_nan(row['Phase2_download_url']):\n",
        "    url = row['Phase1_download_url']\n",
        "    year = row['Phase1_year']\n",
        "  else:\n",
        "    url = row['Phase2_download_url']\n",
        "    year = row['Phase2_year']\n",
        "  uploaded_file_name = f'{MAIN_DIR}/ky/KY_{year}_{tile_ID}.laz'\n",
        "  uploaded_file = bucket.blob(uploaded_file_name)\n",
        "  if not uploaded_file.exists():\n",
        "    max_retries = 3\n",
        "    for attempt in range(max_retries):\n",
        "      try:\n",
        "        with requests.get(url, stream=True) as response: # Avoids downloading the file locally\n",
        "                if response.status_code == 200:\n",
        "                    uploaded_file.upload_from_file(response.raw)\n",
        "                    break\n",
        "      except requests.exceptions.RequestException as e: # Tries again if after waiting 5 sec if there is a connection error\n",
        "        time.sleep(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7fP1m1YdQRn"
      },
      "outputs": [],
      "source": [
        "# Parallelize for speed\n",
        "num_processes = 8\n",
        "\n",
        "with Pool(num_processes) as pool:\n",
        "        pool.map(scrape, rows)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
